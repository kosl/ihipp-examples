{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQgWDjKRv7Y"
   },
   "source": [
    "## CUDA Vector addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jNWhdlcMTsqf",
    "outputId": "1752ddf4-455d-4368-fdd5-e6611465bd70"
   },
   "outputs": [],
   "source": [
    " %%file vector_add_cuda.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define N 2020\n",
    "#define MAX_ERR 1e-6\n",
    "\n",
    "__global__ void vector_add(double *out, double *a, double *b, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(i < n)\n",
    "        out[i] = a[i] + b[i];\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    double *a, *b, *out;\n",
    "    double *d_a, *d_b, *d_out; \n",
    "\n",
    "    // Allocate host memory\n",
    "    a   = (double*)malloc(sizeof(double) * N);\n",
    "    b   = (double*)malloc(sizeof(double) * N);\n",
    "    out = (double*)malloc(sizeof(double) * N);\n",
    "\n",
    "    // Initialize host arrays\n",
    "    for(int i = 0; i < N; i++){\n",
    "        a[i] = i / 100.0;\n",
    "        b[i] = (N - i) / 100.0;\n",
    "    }\n",
    "\n",
    "    // Allocate device memory\n",
    "    cudaMalloc((void**)&d_a, sizeof(double) * N);\n",
    "    cudaMalloc((void**)&d_b, sizeof(double) * N);\n",
    "    cudaMalloc((void**)&d_out, sizeof(double) * N);\n",
    "\n",
    "    // Transfer data from host to device memory\n",
    "    cudaMemcpy(d_a, a, sizeof(double) * N, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, sizeof(double) * N, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Executing kernel\n",
    "    int threadsPerBlock = 1024;\n",
    "    //int blocksPerGrid =(N + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    int blocksPerGrid = N/threadsPerBlock + (N % threadsPerBlock == 0 ? 0:1);\n",
    "    vector_add<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_a, d_b, N);\n",
    "    \n",
    "    // Transfer data back to host memory\n",
    "    cudaMemcpy(out, d_out, sizeof(double) * N, cudaMemcpyDeviceToHost);\n",
    "     \n",
    "    // Verification\n",
    "    for(int i = 0; i < N; i++){\n",
    "        assert(fabs(out[i] - a[i] - b[i]) < MAX_ERR);\n",
    "        if (i % 101 == 0)\n",
    "          printf(\"%.2f + %.2f = %.2f\\n\", a[i], b[i], out[i]);\n",
    "    }\n",
    "    printf(\"PASSED\\n\");\n",
    "\n",
    "    // Deallocate device memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_out);\n",
    "\n",
    "    // Deallocate host memory\n",
    "    free(a); \n",
    "    free(b); \n",
    "    free(out);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN8oYyTfUOhe",
    "outputId": "f1b96317-6bb9-4202-dcd8-c36cf6b4b42c"
   },
   "outputs": [],
   "source": [
    "!PATH=/usr/local/cuda-10.1/bin:${PATH} nvcc -o vector_add_cuda vector_add_cuda.cu && ./vector_add_cuda"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Vector_addition_CUDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
