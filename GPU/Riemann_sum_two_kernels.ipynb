{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Suh22TEsvu3r"
   },
   "source": [
    "## Numerical integration (Riemann sum): calculating $\\Phi(1) = \\frac 1 {\\sqrt{2\\pi}} \\int_{0}^1 e^{-x^2/2} \\, dx$\n",
    "(see, e.g.: https://mathworld.wolfram.com/NormalDistributionFunction.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSm_RusNcfxh"
   },
   "source": [
    "#### CUDA version with two kernels (trapezoid median + sum reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_1m3cMnfG5F",
    "outputId": "2407962a-63e3-4abb-c872-983df849a36e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting riemann_cuda_double_reduce.cu\n"
     ]
    }
   ],
   "source": [
    "%%file riemann_cuda_double_reduce.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <device_launch_parameters.h>\n",
    "\n",
    "#define N 100000000\n",
    "\n",
    "/* CUDA error wraper */\n",
    "static void CUDA_ERROR( cudaError_t err) \n",
    "{\n",
    "    if (err != cudaSuccess) {\n",
    "        printf(\"CUDA ERROR: %s, exiting\\n\", cudaGetErrorString(err));\n",
    "        exit(-1);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void medianTrapezoid(double *a, int n)\n",
    "{\n",
    "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  double x = (double)idx / (double)n;\n",
    " \n",
    "  if(idx < n)\n",
    "    a[idx] = (exp(-x * x / 2.0) + exp(-(x + 1 / (double)n) * (x + 1 / (double)n) / 2.0)) / 2.0;\n",
    "}\n",
    "\n",
    "__global__ void reducerSum(double *a, double *out, int n, int block_size) {\n",
    "    int idx = threadIdx.x;\n",
    "    double sum = 0;\n",
    "    for (int i = idx; i < n; i += block_size)\n",
    "        sum += a[i];\n",
    "    extern __shared__ double r[];\n",
    "    r[idx] = sum;\n",
    "    __syncthreads();\n",
    "    for (int size = block_size/2; size>0; size/=2) {\n",
    "        if (idx<size)\n",
    "            r[idx] += r[idx+size];\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (idx == 0)\n",
    "        *out = r[0];\n",
    "}\n",
    "\n",
    "double riemannCUDA(int n)\n",
    "{\n",
    "  ///size of the arrays in bytes\n",
    "  size_t size = n * sizeof(double);\n",
    "\n",
    "  int block_size = 1024;\n",
    "\n",
    "  // allocate array on host and device\n",
    "  double* a_h = (double *)malloc(size);\n",
    "  double* out_h = (double *)malloc(sizeof(double));\n",
    "  double* r = (double *)malloc(block_size * sizeof(double));\n",
    "  double* a_d; cudaMalloc((double **) &a_d, size);\n",
    "  double* out; cudaMalloc((double **) &out, sizeof(double));\n",
    "\n",
    "  // do calculation on device\n",
    "  \n",
    "  int n_blocks = n/block_size + (n % block_size == 0 ? 0:1);\n",
    "  printf(\"CUDA kernel 'medianTrapezoid' launch with %d blocks of %d threads\\n\", n_blocks, block_size);\n",
    "  medianTrapezoid <<< n_blocks, block_size >>> (a_d, n);\n",
    "  int n_blocks2 = 1;\n",
    "  printf(\"CUDA kernel 'reducerSum' launch with %d blocks of %d threads\\n\\n\", n_blocks2, block_size);\n",
    "  reducerSum <<< n_blocks2, block_size, block_size*sizeof(double) >>> (a_d, out, n, block_size);\n",
    "  \n",
    "  // copy results from device to host\n",
    "  cudaMemcpy(out_h, out, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "  // add up results\n",
    "  double sum;\n",
    "  sum = *out_h;\n",
    "  sum *= (1.0 / sqrt(2.0 * M_PI)) / (double)n;\n",
    "  \n",
    "  // clean up\n",
    "  free(a_h); cudaFree(a_d);\n",
    "  free(out_h); cudaFree(out);\n",
    "  cudaFree(r);\n",
    "  \n",
    "  return sum;\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "  /*get info on our GPU, defaulting to first one*/\n",
    "  cudaDeviceProp prop;\n",
    "  CUDA_ERROR(cudaGetDeviceProperties(&prop,0));\n",
    "  printf(\"Found GPU '%s' with %g GB of global memory, max %d threads per block, and %d multiprocessors\\n\", \n",
    "         prop.name, prop.totalGlobalMem/(1024.0*1024.0*1024.0),\n",
    "         prop.maxThreadsPerBlock,prop.multiProcessorCount);\n",
    " \n",
    "  /*init CUDA*/\n",
    "  CUDA_ERROR(cudaSetDevice(0));\n",
    "\n",
    "  clock_t t1; \n",
    "  t1 = clock();\n",
    "\n",
    "  double sum = riemannCUDA(N);\n",
    "\n",
    "  t1 = clock() - t1;\n",
    "\n",
    "  double time_taken1 = ((double)t1)/CLOCKS_PER_SEC; // in seconds\n",
    "\n",
    "  printf(\"Riemann sum CUDA (double precision) for N = %d    : %.17g \\n\", N, sum);\n",
    "  printf(\"Total time (measured by CPU)                              : %f s\\n\", time_taken1);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIzDk6iVff23",
    "outputId": "a557be2d-d1bb-415a-b400-5e6264df4d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU 'Quadro P400' with 2 GB of global memory, max 1024 threads per block, and 2 multiprocessors\n",
      "CUDA kernel 'medianTrapezoid' launch with 97657 blocks of 1024 threads\n",
      "CUDA kernel 'reducerSum' launch with 1 blocks of 1024 threads\n",
      "\n",
      "Riemann sum CUDA (double precision) for N = 100000000    : 0.34134474606854298 \n",
      "Total time (measured by CPU)                              : 0.628118 s\n"
     ]
    }
   ],
   "source": [
    "!PATH=/usr/local/cuda-10.1/bin:${PATH} nvcc -o riemann_cuda_double_reduce riemann_cuda_double_reduce.cu && ./riemann_cuda_double_reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADXNL1q2u7it"
   },
   "source": [
    "#### OpenCL version with two kernels (trapezoid median + sum reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6bzLr8hsqP_",
    "outputId": "af759d0d-861f-43e2-9c15-8e939861ea06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting riemann_reduce.cl\n"
     ]
    }
   ],
   "source": [
    "%%file riemann_reduce.cl\n",
    "__kernel void medianTrapezoid(__global double *a, int n) {\n",
    "    \n",
    "    int idx = get_global_id(0);\n",
    "    double x = (double)idx / (double)n;\n",
    " \n",
    "    if(idx < n)\n",
    "       a[idx] = (exp(-x * x / 2.0) + exp(-(x + 1 / (double)n) * (x + 1 / (double)n) / 2.0)) / 2.0;\n",
    "}\n",
    "\n",
    "__kernel void reducerSum(__global double *a, __global double *out, __local double *r, int n, int block_size)\n",
    "{\n",
    "    int idx = get_local_id(0);\n",
    "    double sum = 0;\n",
    "    for (int i = idx; i < n; i += block_size)\n",
    "        sum += a[i];\n",
    "    r[idx] = sum;\n",
    "    barrier(CLK_LOCAL_MEM_FENCE);\n",
    "\n",
    "    for (int size = block_size/2; size>0; size/=2) {\n",
    "        if (idx<size)\n",
    "            r[idx] += r[idx+size];\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    "   \n",
    "    if (idx == 0)\n",
    "        *out = r[0];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting riemann_opencl_double_reduce.c\n"
     ]
    }
   ],
   "source": [
    "%%file riemann_opencl_double_reduce.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <CL/cl.h>\n",
    "\n",
    "#define MAX_SOURCE_SIZE (0x100000)\n",
    "\n",
    "#define N 100000000\n",
    "\n",
    "double riemannCL(int n)\n",
    "{\n",
    "    //Allocate memory to host variable\n",
    "    int block_size = 256;\n",
    "    double *a = (double*)malloc(sizeof(double) * n);\n",
    "    double *out = (double*)malloc(sizeof(double));\n",
    "    \n",
    "    // Load the kernel source code into the array source_str\n",
    "    FILE *fp;\n",
    "    char *source_str;\n",
    "    size_t source_size;\n",
    "\n",
    "    fp = fopen(\"riemann_reduce.cl\", \"r\");\n",
    "    if (!fp) {\n",
    "        fprintf(stderr, \"Failed to load kernel.\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "    source_str = (char*)malloc(MAX_SOURCE_SIZE);\n",
    "    source_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n",
    "    fclose( fp );\n",
    "\n",
    "    // Get platform and device information\n",
    "    cl_platform_id platform_id = NULL;\n",
    "    cl_device_id device_id = NULL;   \n",
    "    cl_uint ret_num_devices;\n",
    "    cl_uint ret_num_platforms;\n",
    "    cl_int ret = clGetPlatformIDs(1, &platform_id, &ret_num_platforms);\n",
    "    ret = clGetDeviceIDs( platform_id, CL_DEVICE_TYPE_ALL, 1, \n",
    "            &device_id, &ret_num_devices);\n",
    "\n",
    "    // Create an OpenCL context\n",
    "    cl_context context = clCreateContext( NULL, 1, &device_id, NULL, NULL, &ret);\n",
    "\n",
    "    // Create a command queue\n",
    "    cl_command_queue command_queue = clCreateCommandQueue(context, device_id, 0, &ret);\n",
    "\n",
    "    // Create memory buffers on the device for each vector \n",
    "    cl_mem a_mem_obj = clCreateBuffer(context, CL_MEM_READ_WRITE, \n",
    "            n * sizeof(double), NULL, &ret);\n",
    "    cl_mem out_mem_obj = clCreateBuffer(context, CL_MEM_READ_WRITE, \n",
    "            sizeof(double), NULL, &ret);\n",
    "\n",
    "    // Create a program from the kernel source\n",
    "    cl_program program = clCreateProgramWithSource(context, 1, \n",
    "            (const char **)&source_str, (const size_t *)&source_size, &ret);\n",
    "\n",
    "    // Build the program\n",
    "    ret = clBuildProgram(program, 1, &device_id, NULL, NULL, NULL);\n",
    "\n",
    "    clock_t t2; \n",
    "    t2 = clock(); \n",
    "\n",
    "    // Create the OpenCL kernel\n",
    "    cl_kernel kernel = clCreateKernel(program, \"medianTrapezoid\", &ret);\n",
    "\n",
    "    // Set the arguments of the kernel\n",
    "    ret = clSetKernelArg(kernel, 0, sizeof(cl_mem), (void *)&a_mem_obj);    \n",
    "    ret = clSetKernelArg(kernel, 1, sizeof(cl_int), (void *)&n);\n",
    "    \n",
    "    // Execute the OpenCL kernel\n",
    "    size_t local_item_size = block_size;\n",
    "    int n_blocks = n/local_item_size + (n % local_item_size == 0 ? 0:1);\n",
    "    size_t global_item_size = n_blocks * local_item_size;\n",
    "    printf(\"OpenCL kernel 'medianTrapezoid' launch with %d blocks of %lu threads\\n\", n_blocks, local_item_size);\n",
    "\n",
    "    ret = clEnqueueNDRangeKernel(command_queue, kernel, 1, NULL, \n",
    "            &global_item_size, &local_item_size, 0, NULL, NULL);\n",
    "\n",
    "    // Create the OpenCL kernel2\n",
    "    cl_kernel kernel2 = clCreateKernel(program, \"reducerSum\", &ret);\n",
    "\n",
    "    // Set the arguments of the kernel2\n",
    "    ret = clSetKernelArg(kernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);    \n",
    "    ret = clSetKernelArg(kernel2, 1, sizeof(cl_mem), (void *)&out_mem_obj);   \n",
    "    ret = clSetKernelArg(kernel2, 2, block_size * sizeof(cl_double), NULL);    \n",
    "    ret = clSetKernelArg(kernel2, 3, sizeof(cl_int), (void *)&n);   \n",
    "    ret = clSetKernelArg(kernel2, 4, sizeof(cl_int), (void *)&block_size);\n",
    "\n",
    "    // Execute the OpenCL kernel2\n",
    "    size_t local_item_size2 = block_size;\n",
    "    size_t global_item_size2 = block_size;\n",
    "    printf(\"OpenCL kernel 'reducerSum' launch with %lu blocks of %lu threads\\n\\n\", global_item_size2/local_item_size2, local_item_size2);\n",
    "\n",
    "    ret = clEnqueueNDRangeKernel(command_queue, kernel2, 1, NULL, \n",
    "            &global_item_size2, &local_item_size2, 0, NULL, NULL);\n",
    "\n",
    "    t2 = clock() - t2;\n",
    "\n",
    "    double time_taken2 = ((double)t2)/CLOCKS_PER_SEC; // in seconds\n",
    "\n",
    "    clock_t t3; \n",
    "    t3 = clock();\n",
    "\n",
    "   \n",
    "    ret = clEnqueueReadBuffer(command_queue, out_mem_obj, CL_TRUE, 0, \n",
    "            sizeof(double), out, 0, NULL, NULL);\n",
    "\n",
    "    t3 = clock() - t3;\n",
    "\n",
    "    double time_taken3 = ((double)t3)/CLOCKS_PER_SEC; // in seconds\n",
    "\n",
    "    // add up results\n",
    "    double sum;\n",
    "    sum = *out;\n",
    "    sum *= (1.0 / sqrt(2.0 * M_PI)) / (double)n;\n",
    "\n",
    "    // Clean up\n",
    "    ret = clFlush(command_queue);\n",
    "    ret = clFinish(command_queue);\n",
    "    ret = clReleaseKernel(kernel);\n",
    "    ret = clReleaseKernel(kernel2);\n",
    "    ret = clReleaseProgram(program);\n",
    "    ret = clReleaseMemObject(a_mem_obj);\n",
    "    ret = clReleaseMemObject(out_mem_obj);\n",
    "    ret = clReleaseCommandQueue(command_queue);\n",
    "    ret = clReleaseContext(context);\n",
    "    free(a);\n",
    "\n",
    "    printf(\"OpenCL and CPU code diagnostics:\\n\");\n",
    "    printf(\"OpenCL kernels execution time (measured by CPU):        %f ms\\n\", time_taken2 * 1000);\n",
    "    printf(\"Device to host memory transfer time (measured by CPU):  %f s\\n\\n\", time_taken3);\n",
    "  \n",
    "    return sum;\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "  clock_t t1; \n",
    "  t1 = clock(); \n",
    "\n",
    "  double sum = riemannCL(N);\n",
    "\n",
    "  t1 = clock() - t1;\n",
    "\n",
    "  double time_taken1 = ((double)t1)/CLOCKS_PER_SEC; // in seconds\n",
    "\n",
    "  printf(\"Riemann sum OpenCL (double precision) for N = %d    : %.17g \\n\", N, sum);\n",
    "  printf(\"Total time (measured by CPU)                                : %f s\\n\", time_taken1);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCL kernel 'medianTrapezoid' launch with 390625 blocks of 256 threads\n",
      "OpenCL kernel 'reducerSum' launch with 1 blocks of 256 threads\n",
      "\n",
      "OpenCL and CPU code diagnostics:\n",
      "OpenCL kernels execution time (measured by CPU):        0.477000 ms\n",
      "Device to host memory transfer time (measured by CPU):  0.365489 s\n",
      "\n",
      "Riemann sum OpenCL (double precision) for N = 100000000    : 0.34134474606854376 \n",
      "Total time (measured by CPU)                                : 0.623706 s\n"
     ]
    }
   ],
   "source": [
    "!nvcc -o riemann_opencl_double_reduce riemann_opencl_double_reduce.c -lOpenCL && ./riemann_opencl_double_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Riemann_sum_CUDA_two_kernels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
