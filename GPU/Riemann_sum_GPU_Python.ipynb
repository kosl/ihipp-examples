{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfy7RP9zkxXH"
      },
      "source": [
        "pip -q install pycuda"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbAk3CRok2oQ",
        "outputId": "c63c9d6e-a7a2-460b-9dc8-fd453c9138d1"
      },
      "source": [
        "%%file riemann_pycuda.py\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import time\n",
        "\n",
        "import numpy\n",
        "\n",
        "def iDivUp(a, b):\n",
        "    return a // b + 1\n",
        "\n",
        "N = 1000000000\n",
        "\n",
        "def riemannCUDA(n):\n",
        "    a = numpy.empty([n])\n",
        "\n",
        "    a = a.astype(numpy.float64)\n",
        "\n",
        "    a_d = cuda.mem_alloc(a.size * a.dtype.itemsize)\n",
        "\n",
        "    mod = SourceModule(\"\"\"\n",
        "        __global__ void medianTrapezoid(double *a, int n)\n",
        "        {\n",
        "          int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "          double x = (double)idx / (double)n;\n",
        " \n",
        "          if(idx < n)\n",
        "            a[idx] = (exp(-x * x / 2.0) + exp(-(x + 1 / (double)n) * (x + 1 / (double)n) / 2.0)) / 2.0;\n",
        "        }\n",
        "        \"\"\")\n",
        "\n",
        "    func = mod.get_function(\"medianTrapezoid\")\n",
        "    block_size = 1024\n",
        "    n_blocks = iDivUp(n, block_size)\n",
        "    blockDim  = (block_size, 1, 1)\n",
        "    gridDim   = (n_blocks, 1, 1)\n",
        "    print(\"CUDA kernel 'medianTrapezoid' launch with %i blocks of %i threads\\n\" % (n_blocks, block_size))\n",
        "    func(a_d, numpy.int32(n), block=blockDim, grid=gridDim)\n",
        "\n",
        "    cuda.memcpy_dtoh(a, a_d)\n",
        "\n",
        "    Sum = numpy.sum(a) / numpy.sqrt(2 * numpy.pi) / numpy.float64(n)\n",
        "\n",
        "    return Sum\n",
        "\n",
        "dev = pycuda.autoinit.device\n",
        "\n",
        "dev_name = dev.name()\n",
        "total_memory = dev.total_memory() / 1024.0 / 1024.0 / 1024.0\n",
        "threads_per_block = dev.get_attribute(pycuda.driver.device_attribute.MAX_THREADS_PER_BLOCK)\n",
        "sm_count = dev.get_attribute(pycuda.driver.device_attribute.MULTIPROCESSOR_COUNT)\n",
        "\n",
        "print(\"Found GPU '%s' with %.3f GB of global memory, max %i threads per block, and %i multiprocessors\\n\" % \n",
        "       (dev_name, total_memory, threads_per_block, sm_count))\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "Sum = riemannCUDA(N)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "time_taken = end - start # in seconds\n",
        "\n",
        "print(\"Riemann sum pyCUDA (double precision) for N = %i  : %.17f\" % (N, Sum));\n",
        "print(\"Total time (measured by CPU)                              : %f s\" % time_taken);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting riemann_pycuda.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GYXOGc7k45d",
        "outputId": "a91533b0-c4ac-42f8-8ae3-3d2f4f51bb77"
      },
      "source": [
        "!PATH=/usr/local/cuda-10.1/bin:${PATH} python riemann_pycuda.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU 'Tesla K80' with 11.173 GB of global memory, max 1024 threads per block, and 13 multiprocessors\n",
            "\n",
            "tcmalloc: large alloc 8000004096 bytes == 0x55753eaf0000 @  0x7fcc6d7df1e7 0x7fcc6b39f46e 0x7fcc6b3efc7b 0x7fcc6b3f035f 0x7fcc6b492103 0x55753bb304b0 0x55753bb30240 0x55753bba40f3 0x55753bb31afa 0x55753bb9f915 0x55753bb9e9ee 0x55753bb9e6f3 0x55753bc684c2 0x55753bc6883d 0x55753bc686e6 0x55753bc40163 0x55753bc3fe0c 0x7fcc6c5c9bf7 0x55753bc3fcea\n",
            "tcmalloc: large alloc 8000004096 bytes == 0x55771c16a000 @  0x7fcc6d7df1e7 0x7fcc6b39f46e 0x7fcc6b3efc7b 0x7fcc6b3efd97 0x7fcc6b488887 0x55753bb304b0 0x55753bc21e1d 0x55753bba3e99 0x55753bb31afa 0x55753bb9f915 0x55753bb9e9ee 0x55753bb9e6f3 0x55753bc684c2 0x55753bc6883d 0x55753bc686e6 0x55753bc40163 0x55753bc3fe0c 0x7fcc6c5c9bf7 0x55753bc3fcea\n",
            "CUDA kernel 'medianTrapezoid' launch with 976563 blocks of 1024 threads\n",
            "\n",
            "Riemann sum pyCUDA (double precision) for N = 1000000000  : 0.34134474606853665\n",
            "Total time (measured by CPU)                              : 4.843949 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN-EHfKQl91a"
      },
      "source": [
        "pip -q install pyopencl"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSzLEAx8l-L7",
        "outputId": "510a18aa-6fff-4d8e-d84f-f5d825974824"
      },
      "source": [
        "%%file riemann_pyopencl.py\n",
        "from __future__ import absolute_import, print_function\n",
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "\n",
        "import time\n",
        "\n",
        "def iDivUp(a, b):\n",
        "    return a // b + 1\n",
        "\n",
        "N = 1000000000\n",
        "\n",
        "def riemannOpenCL(n):\n",
        "\n",
        "    a = np.empty([n])\n",
        "    a = a.astype(np.float64)\n",
        "\n",
        "    queue = cl.CommandQueue(ctx)\n",
        "\n",
        "    mf = cl.mem_flags\n",
        "    a_d = cl.Buffer(ctx, mf.WRITE_ONLY, a.nbytes)\n",
        "\n",
        "    prg = cl.Program(ctx, \"\"\"\n",
        "    __kernel void medianTrapezoid(__global double *a, int n) {\n",
        "    \n",
        "        int idx = get_global_id(0);\n",
        "        double x = (double)idx / (double)n;\n",
        " \n",
        "        if(idx < n)\n",
        "           a[idx] = (exp(-x * x / 2.0) + exp(-(x + 1 / (double)n) * (x + 1 / (double)n) / 2.0)) / 2.0;\n",
        "    }\n",
        "    \"\"\").build()\n",
        "\n",
        "    local_item_size = 1024\n",
        "    n_blocks = iDivUp(n, local_item_size)\n",
        "    global_item_size = n_blocks * local_item_size\n",
        "    print(\"OpenCL kernel 'medianTrapezoid' launch with %i blocks of %i threads\\n\" % (n_blocks, local_item_size))\n",
        "    prg.medianTrapezoid(queue, (global_item_size, 1, 1), (local_item_size, 1, 1), a_d, np.int32(n))\n",
        "\n",
        "    cl.enqueue_copy(queue, a, a_d)\n",
        "\n",
        "    Sum = np.sum(a) / np.sqrt(2 * np.pi) / np.float64(n)\n",
        "\n",
        "    return Sum\n",
        "\n",
        "platform = cl.get_platforms()[0]\n",
        "device = platform.get_devices()[0]\n",
        "ctx = cl.Context([device])\n",
        "\n",
        "dev_name = device.name\n",
        "total_memory = device.global_mem_size / 1024.0 / 1024.0 / 1024.0\n",
        "threads_per_block = device.max_work_group_size\n",
        "sm_count = device.max_compute_units\n",
        "\n",
        "print(\"Found GPU '%s' with %.3f GB of global memory, max %i threads per block, and %i multiprocessors\\n\" % \n",
        "       (dev_name, total_memory, threads_per_block, sm_count))\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "Sum = riemannOpenCL(N)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "time_taken = end - start # in seconds\n",
        "\n",
        "print(\"Riemann sum pyOpenCL (double precision) for N = %i  : %.17f\" % (N, Sum));\n",
        "print(\"Total time (measured by CPU)                                : %f s\" % time_taken);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting riemann_pyopencl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucuDiRLPl-im",
        "outputId": "3aee497e-a44d-4746-bc40-d0cfe853c5a7"
      },
      "source": [
        "!PATH=/usr/local/cuda-10.1/bin:${PATH} python riemann_pyopencl.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU 'Tesla K80' with 11.173 GB of global memory, max 1024 threads per block, and 13 multiprocessors\n",
            "\n",
            "tcmalloc: large alloc 8000004096 bytes == 0x561c88ad4000 @  0x7f3022a501e7 0x7f302061046e 0x7f3020660c7b 0x7f302066135f 0x7f3020703103 0x561c861f14b0 0x561c861f1240 0x561c862650f3 0x561c861f2afa 0x561c86260915 0x561c8625f9ee 0x561c8625f6f3 0x561c863294c2 0x561c8632983d 0x561c863296e6 0x561c86301163 0x561c86300e0c 0x7f302183abf7 0x561c86300cea\n",
            "tcmalloc: large alloc 8000004096 bytes == 0x561e661cc000 @  0x7f3022a501e7 0x7f302061046e 0x7f3020660c7b 0x7f3020660d97 0x7f30206f9887 0x561c861f14b0 0x561c862e2e1d 0x561c86264e99 0x561c861f2afa 0x561c86260915 0x561c8625f9ee 0x561c8625f6f3 0x561c863294c2 0x561c8632983d 0x561c863296e6 0x561c86301163 0x561c86300e0c 0x7f302183abf7 0x561c86300cea\n",
            "OpenCL kernel 'medianTrapezoid' launch with 976563 blocks of 1024 threads\n",
            "\n",
            "Riemann sum pyOpenCL (double precision) for N = 1000000000  : 0.34134474606853665\n",
            "Total time (measured by CPU)                                : 5.246449 s\n"
          ]
        }
      ]
    }
  ]
}