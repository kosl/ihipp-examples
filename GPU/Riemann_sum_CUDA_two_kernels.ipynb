{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Riemann_sum_CUDA_two_kernels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suh22TEsvu3r"
      },
      "source": [
        "## Numerical integration (Riemann sum): calculating $\\Phi(1) = \\frac 1 {\\sqrt{2\\pi}} \\int_{0}^1 e^{-x^2/2} \\, dx$\n",
        "(see, e.g.: https://mathworld.wolfram.com/NormalDistributionFunction.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSm_RusNcfxh"
      },
      "source": [
        "#### CUDA version with two kernels (trapezoid median + sum reducer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_1m3cMnfG5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2407962a-63e3-4abb-c872-983df849a36e"
      },
      "source": [
        "%%file riemann_cuda_double_reduce.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "\n",
        "#define N 1000000000\n",
        "\n",
        "/* CUDA error wraper */\n",
        "static void CUDA_ERROR( cudaError_t err) \n",
        "{\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"CUDA ERROR: %s, exiting\\n\", cudaGetErrorString(err));\n",
        "        exit(-1);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void medianTrapezoid(double *a, int n)\n",
        "{\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  double x = (double)idx / (double)n;\n",
        " \n",
        "  if(idx < n)\n",
        "    a[idx] = (exp(-x * x / 2.0) + exp(-(x + 1 / (double)n) * (x + 1 / (double)n) / 2.0)) / 2.0;\n",
        "}\n",
        "\n",
        "__global__ void reducerSum(double *a, double *out, int n, int block_size) {\n",
        "    int idx = threadIdx.x;\n",
        "    double sum = 0;\n",
        "    for (int i = idx; i < n; i += block_size)\n",
        "        sum += a[i];\n",
        "    extern __shared__ double r[];\n",
        "    r[idx] = sum;\n",
        "    __syncthreads();\n",
        "    for (int size = block_size/2; size>0; size/=2) {\n",
        "        if (idx<size)\n",
        "            r[idx] += r[idx+size];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (idx == 0)\n",
        "        *out = r[0];\n",
        "}\n",
        "\n",
        "double riemannCUDA(int n)\n",
        "{\n",
        "  ///size of the arrays in bytes\n",
        "  size_t size = n * sizeof(double);\n",
        "\n",
        "  int block_size = 1024;\n",
        "\n",
        "  // allocate array on host and device\n",
        "  double* a_h = (double *)malloc(size);\n",
        "  double* out_h = (double *)malloc(sizeof(double));\n",
        "  double* r = (double *)malloc(block_size * sizeof(double));\n",
        "  double* a_d; cudaMalloc((double **) &a_d, size);\n",
        "  double* out; cudaMalloc((double **) &out, sizeof(double));\n",
        "\n",
        "  // do calculation on device\n",
        "  \n",
        "  int n_blocks = n/block_size + (n % block_size == 0 ? 0:1);\n",
        "  printf(\"CUDA kernel 'medianTrapezoid' launch with %d blocks of %d threads\\n\", n_blocks, block_size);\n",
        "  medianTrapezoid <<< n_blocks, block_size >>> (a_d, n);\n",
        "  int n_blocks2 = 1;\n",
        "  printf(\"CUDA kernel 'reducerSum' launch with %d blocks of %d threads\\n\\n\", n_blocks2, block_size);\n",
        "  reducerSum <<< n_blocks2, block_size, block_size*sizeof(double) >>> (a_d, out, n, block_size);\n",
        "  \n",
        "  // copy results from device to host\n",
        "  cudaMemcpy(out_h, out, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // add up results\n",
        "  double sum;\n",
        "  sum = *out_h;\n",
        "  sum *= (1.0 / sqrt(2.0 * M_PI)) / (double)n;\n",
        "  \n",
        "  // clean up\n",
        "  free(a_h); cudaFree(a_d);\n",
        "  free(out_h); cudaFree(out);\n",
        "  cudaFree(r);\n",
        "  \n",
        "  return sum;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "\n",
        "  /*get info on our GPU, defaulting to first one*/\n",
        "  cudaDeviceProp prop;\n",
        "  CUDA_ERROR(cudaGetDeviceProperties(&prop,0));\n",
        "  printf(\"Found GPU '%s' with %g GB of global memory, max %d threads per block, and %d multiprocessors\\n\", \n",
        "         prop.name, prop.totalGlobalMem/(1024.0*1024.0*1024.0),\n",
        "         prop.maxThreadsPerBlock,prop.multiProcessorCount);\n",
        " \n",
        "  /*init CUDA*/\n",
        "  CUDA_ERROR(cudaSetDevice(0));\n",
        "\n",
        "  clock_t t1; \n",
        "  t1 = clock();\n",
        "\n",
        "  double sum = riemannCUDA(N);\n",
        "\n",
        "  t1 = clock() - t1;\n",
        "\n",
        "  double time_taken1 = ((double)t1)/CLOCKS_PER_SEC; // in seconds\n",
        "\n",
        "  printf(\"Riemann sum CUDA (double precision) for N = %d    : %.17g \\n\", N, sum);\n",
        "  printf(\"Total time (measured by CPU)                              : %f s\\n\", time_taken1);\n",
        "}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting riemann_cuda_double_reduce.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIzDk6iVff23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a557be2d-d1bb-415a-b400-5e6264df4d7d"
      },
      "source": [
        "!PATH=/usr/local/cuda-10.1/bin:${PATH} nvcc -o riemann_cuda_double_reduce riemann_cuda_double_reduce.cu && ./riemann_cuda_double_reduce"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU 'Tesla K80' with 11.173 GB of global memory, max 1024 threads per block, and 13 multiprocessors\n",
            "tcmalloc: large alloc 8000004096 bytes == 0x556703572000 @  0x7fc9a2b2c1e7 0x55670169db76 0x55670169de96 0x7fc9a1b5dbf7 0x55670169d9ea\n",
            "CUDA kernel 'medianTrapezoid' launch with 976563 blocks of 1024 threads\n",
            "CUDA kernel 'reducerSum' launch with 1 blocks of 1024 threads\n",
            "\n",
            "Riemann sum CUDA (double precision) for N = 1000000000    : 0.34134474606854243 \n",
            "Total time (measured by CPU)                              : 1.518359 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADXNL1q2u7it"
      },
      "source": [
        "#### CUDA profiling (trapezoid median + sum reducer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6bzLr8hsqP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af759d0d-861f-43e2-9c15-8e939861ea06"
      },
      "source": [
        "!nvprof ./riemann_cuda_double_reduce"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==295== NVPROF is profiling process 295, command: ./riemann_cuda_double_reduce\n",
            "Found GPU 'Tesla K80' with 11.173 GB of global memory, max 1024 threads per block, and 13 multiprocessors\n",
            "tcmalloc: large alloc 8000004096 bytes == 0x55c12f3d0000 @  0x7fb20bc551e7 0x55c12b364b76 0x55c12b364e96 0x7fb20ac86bf7 0x55c12b3649ea\n",
            "==295== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "CUDA kernel 'medianTrapezoid' launch with 976563 blocks of 1024 threads\n",
            "CUDA kernel 'reducerSum' launch with 1 blocks of 1024 threads\n",
            "\n",
            "==295== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version \n",
            "Riemann sum CUDA (double precision) for N = 1000000000    : 0.34134474606854243 \n",
            "Total time (measured by CPU)                              : 1.460210 s\n",
            "==295== Profiling application: ./riemann_cuda_double_reduce\n",
            "==295== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   80.65%  484.47ms         1  484.47ms  484.47ms  484.47ms  reducerSum(double*, double*, int, int)\n",
            "                   19.35%  116.24ms         1  116.24ms  116.24ms  116.24ms  medianTrapezoid(double*, int)\n",
            "                    0.00%  3.2320us         1  3.2320us  3.2320us  3.2320us  [CUDA memcpy DtoH]\n",
            "      API calls:   45.02%  656.75ms         3  218.92ms  20.683us  649.23ms  cudaFree\n",
            "                   41.18%  600.73ms         1  600.73ms  600.73ms  600.73ms  cudaMemcpy\n",
            "                   13.72%  200.08ms         2  100.04ms  191.49us  199.89ms  cudaMalloc\n",
            "                    0.04%  532.61us         1  532.61us  532.61us  532.61us  cuDeviceTotalMem\n",
            "                    0.02%  253.46us         2  126.73us  33.024us  220.44us  cudaLaunchKernel\n",
            "                    0.01%  173.58us        97  1.7890us     163ns  71.612us  cuDeviceGetAttribute\n",
            "                    0.01%  145.66us         1  145.66us  145.66us  145.66us  cudaGetDeviceProperties\n",
            "                    0.00%  23.721us         1  23.721us  23.721us  23.721us  cuDeviceGetName\n",
            "                    0.00%  7.4200us         1  7.4200us  7.4200us  7.4200us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.9660us         1  3.9660us  3.9660us  3.9660us  cudaSetDevice\n",
            "                    0.00%  2.2470us         3     749ns     302ns  1.3200us  cuDeviceGetCount\n",
            "                    0.00%  1.2950us         2     647ns     239ns  1.0560us  cuDeviceGet\n",
            "                    0.00%     306ns         1     306ns     306ns     306ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}