{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Riemann_sum_CUDA_two_kernels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suh22TEsvu3r"
      },
      "source": [
        "## Numerical integration (Riemann sum): calculating $\\Phi(1) = \\frac 1 {\\sqrt{2\\pi}} \\int_{0}^1 e^{-x^2/2} \\, dx$\n",
        "(see, e.g.: https://mathworld.wolfram.com/NormalDistributionFunction.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSm_RusNcfxh"
      },
      "source": [
        "#### CUDA version with two kernels (trapezoid median + sum reducer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_1m3cMnfG5F"
      },
      "source": [
        "%%sh\n",
        "cat > riemann_cuda_double_reduce.cu << EOF\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "\n",
        "#define N 1000000000\n",
        "\n",
        "/* CUDA error wraper */\n",
        "static void CUDA_ERROR( cudaError_t err) \n",
        "{\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"CUDA ERROR: %s, exiting\\n\", cudaGetErrorString(err));\n",
        "        exit(-1);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void medianTrapezoid(double *a, int n)\n",
        "{\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  double x = (double)idx / (double)n;\n",
        " \n",
        "  if(idx < n)\n",
        "    a[idx] = (exp(-x * x / 2.0) + exp(-(x + 1 / (double)n) * (x + 1 / (double)n) / 2.0)) / 2.0;\n",
        "}\n",
        "\n",
        "__global__ void reducerSum(double *a, double *out, int n, int block_size) {\n",
        "    int idx = threadIdx.x;\n",
        "    double sum = 0;\n",
        "    for (int i = idx; i < n; i += block_size)\n",
        "        sum += a[i];\n",
        "    extern __shared__ double r[];\n",
        "    r[idx] = sum;\n",
        "    __syncthreads();\n",
        "    for (int size = block_size/2; size>0; size/=2) {\n",
        "        if (idx<size)\n",
        "            r[idx] += r[idx+size];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (idx == 0)\n",
        "        *out = r[0];\n",
        "}\n",
        "\n",
        "double riemannCUDA(int n)\n",
        "{\n",
        "  ///size of the arrays in bytes\n",
        "  size_t size = n * sizeof(double);\n",
        "\n",
        "  int block_size = 1024;\n",
        "\n",
        "  // allocate array on host and device\n",
        "  double* a_h = (double *)malloc(size);\n",
        "  double* out_h = (double *)malloc(sizeof(double));\n",
        "  double* r = (double *)malloc(block_size * sizeof(double));\n",
        "  double* a_d; cudaMalloc((double **) &a_d, size);\n",
        "  double* out; cudaMalloc((double **) &out, sizeof(double));\n",
        "\n",
        "  // do calculation on device\n",
        "  \n",
        "  int n_blocks = n/block_size + (n % block_size == 0 ? 0:1);\n",
        "  printf(\"CUDA kernel 'medianTrapezoid' launch with %d blocks of %d threads\\n\", n_blocks, block_size);\n",
        "  medianTrapezoid <<< n_blocks, block_size >>> (a_d, n);\n",
        "  int n_blocks2 = 1;\n",
        "  printf(\"CUDA kernel 'reducerSum' launch with %d blocks of %d threads\\n\\n\", n_blocks2, block_size);\n",
        "  reducerSum <<< n_blocks2, block_size, block_size*sizeof(double) >>> (a_d, out, n, block_size);\n",
        "  \n",
        "  // copy results from device to host\n",
        "  cudaMemcpy(out_h, out, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // add up results\n",
        "  double sum;\n",
        "  sum = *out_h;\n",
        "  sum *= (1.0 / sqrt(2.0 * M_PI)) / (double)n;\n",
        "  \n",
        "  // clean up\n",
        "  free(a_h); cudaFree(a_d);\n",
        "  free(out_h); cudaFree(out);\n",
        "  cudaFree(r);\n",
        "  \n",
        "  return sum;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "\n",
        "  /*get info on our GPU, defaulting to first one*/\n",
        "  cudaDeviceProp prop;\n",
        "  CUDA_ERROR(cudaGetDeviceProperties(&prop,0));\n",
        "  printf(\"Found GPU '%s' with %g GB of global memory, max %d threads per block, and %d multiprocessors\\n\", \n",
        "         prop.name, prop.totalGlobalMem/(1024.0*1024.0*1024.0),\n",
        "         prop.maxThreadsPerBlock,prop.multiProcessorCount);\n",
        " \n",
        "  /*init CUDA*/\n",
        "  CUDA_ERROR(cudaSetDevice(0));\n",
        "\n",
        "  clock_t t1; \n",
        "  t1 = clock();\n",
        "\n",
        "  double sum = riemannCUDA(N);\n",
        "\n",
        "  t1 = clock() - t1;\n",
        "\n",
        "  double time_taken1 = ((double)t1)/CLOCKS_PER_SEC; // in seconds\n",
        "\n",
        "  printf(\"Riemann sum CUDA (double precision) for N = %d    : %.17g \\n\", N, sum);\n",
        "  printf(\"Total time (measured by CPU)                              : %f s\\n\", time_taken1);\n",
        "} \n",
        "EOF"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIzDk6iVff23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c7c186-7668-4dc5-ce53-ebc9ea75a7fa"
      },
      "source": [
        "!nvcc -o riemann_cuda_double_reduce riemann_cuda_double_reduce.cu && ./riemann_cuda_double_reduce"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU 'Tesla T4' with 14.7556 GB of global memory, max 1024 threads per block, and 40 multiprocessors\n",
            "tcmalloc: large alloc 8000004096 bytes == 0x55a94fd6e000 @  0x7ff332b8e1e7 0x55a94ee1ee96 0x55a94ee1f1b6 0x7ff331bbfbf7 0x55a94ee1ed0a\n",
            "CUDA kernel 'medianTrapezoid' launch with 976563 blocks of 1024 threads\n",
            "CUDA kernel 'reducerSum' launch with 1 blocks of 1024 threads\n",
            "\n",
            "Riemann sum CUDA (double precision) for N = 1000000000    : 0.34134474606854243 \n",
            "Total time (measured by CPU)                              : 1.122841 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADXNL1q2u7it"
      },
      "source": [
        "#### CUDA profiling (trapezoid median + sum reducer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6bzLr8hsqP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c93c127-b66e-47f2-97c4-b633a0574aae"
      },
      "source": [
        "!nvprof ./riemann_cuda_double_reduce"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==233== NVPROF is profiling process 233, command: ./riemann_cuda_double_reduce\n",
            "Found GPU 'Tesla T4' with 14.7556 GB of global memory, max 1024 threads per block, and 40 multiprocessors\n",
            "tcmalloc: large alloc 8000004096 bytes == 0x5616089a0000 @  0x7f388b58d1e7 0x561604424e96 0x5616044251b6 0x7f388a5bebf7 0x561604424d0a\n",
            "CUDA kernel 'medianTrapezoid' launch with 976563 blocks of 1024 threads\n",
            "CUDA kernel 'reducerSum' launch with 1 blocks of 1024 threads\n",
            "\n",
            "Riemann sum CUDA (double precision) for N = 1000000000    : 0.34134474606854243 \n",
            "Total time (measured by CPU)                              : 1.040373 s\n",
            "==233== Profiling application: ./riemann_cuda_double_reduce\n",
            "==233== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   55.73%  471.54ms         1  471.54ms  471.54ms  471.54ms  medianTrapezoid(double*, int)\n",
            "                   44.27%  374.63ms         1  374.63ms  374.63ms  374.63ms  reducerSum(double*, double*, int, int)\n",
            "                    0.00%  2.4960us         1  2.4960us  2.4960us  2.4960us  [CUDA memcpy DtoH]\n",
            "      API calls:   81.27%  846.19ms         1  846.19ms  846.19ms  846.19ms  cudaMemcpy\n",
            "                   17.98%  187.21ms         2  93.604ms  331.15us  186.88ms  cudaMalloc\n",
            "                    0.67%  6.9842ms         3  2.3281ms  2.0030us  5.8892ms  cudaFree\n",
            "                    0.04%  409.99us         1  409.99us  409.99us  409.99us  cuDeviceTotalMem\n",
            "                    0.02%  157.99us       101  1.5640us     135ns  62.282us  cuDeviceGetAttribute\n",
            "                    0.01%  131.38us         1  131.38us  131.38us  131.38us  cudaGetDeviceProperties\n",
            "                    0.01%  57.273us         2  28.636us  12.009us  45.264us  cudaLaunchKernel\n",
            "                    0.00%  32.852us         1  32.852us  32.852us  32.852us  cuDeviceGetName\n",
            "                    0.00%  5.1180us         1  5.1180us  5.1180us  5.1180us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.0200us         1  3.0200us  3.0200us  3.0200us  cudaSetDevice\n",
            "                    0.00%  1.5180us         2     759ns     257ns  1.2610us  cuDeviceGet\n",
            "                    0.00%  1.4700us         3     490ns     268ns     873ns  cuDeviceGetCount\n",
            "                    0.00%     258ns         1     258ns     258ns     258ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}